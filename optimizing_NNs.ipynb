{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, step=0, name=\"\", info=\"\", image=None):\n",
    "    \"\"\"Fn to visualize the agent playing the game in a notebook\n",
    "    \"\"\"\n",
    "    plt.figure(10)\n",
    "    plt.clf()\n",
    "    if image is not None:\n",
    "        im = image\n",
    "    else:\n",
    "        im = env.render(mode=\"rgb_array\")[0]\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"{} | Step: {} {}\".format(name, step, info))\n",
    "    plt.axis('off')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import optimize\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from optimization.Optimizer import PyTorchObjective\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from utils.diff_evo import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from es import SimpleGA, OpenES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below = np.load('winning_from_below.npy')\n",
    "# above = np.load('winning_from_above.npy')\n",
    "# right = np.load('winning_from_far_right.npy')\n",
    "# monster = np.load('winning_with_monster.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for im in monster:\n",
    "#     show_state(None, image=im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# logging.basicConfig(level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvgai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.levels.base import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.NNagent import NNagent\n",
    "from agent.base import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.env_gen_wrapper import GridGame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = NNagent(GridGame(game='dzelda', \n",
    "                      play_length=1000, \n",
    "                      path='./levels',\n",
    "                      lvl_name='1.txt',\n",
    "                      mechanics=['+', 'g'], # monsters, key, door, wall\n",
    "                      images=False,\n",
    "                  )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wwwwwwwwwwwww\n",
      "w...........w\n",
      "w...........w\n",
      "w.+.........w\n",
      "w.....A.....w\n",
      "w...........w\n",
      "w...........w\n",
      "w.g.........w\n",
      "wwwwwwwwwwwww\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(_x.env.generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _map, shape = _x.env.generator.mutate(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.levels.base import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tile(locations, _length, _height):\n",
    "#     npa = np.array([['w'] * _height] * _length, dtype=str)\n",
    "#     for k in locations.keys():\n",
    "#         for pos in locations[k]:\n",
    "#             npa[pos[0]][pos[1]] = k\n",
    "\n",
    "#     return npa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators = [Generator(tile_world=tile(_x.env.generator.locations, *shape),\n",
    "#                        shape=shape,\n",
    "#                        path='./levels',\n",
    "#                        mechanics=['+', 'g'],\n",
    "#                        generation=0,\n",
    "#                        locations={}) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents = [NNagent(GridGame(game='dzelda', \n",
    "#                               play_length=1000, \n",
    "#                               path='./levels',\n",
    "#                               lvl_name='1.txt',\n",
    "#                               mechanics=['+', 'g'], # monsters, key, door, wall\n",
    "#                               images=False,\n",
    "#                           ), \n",
    "#                   parent=torch.load(\"./dzelda_base_agent_150.pt\")) \n",
    "#           for _ in range(5)]\n",
    "\n",
    "# for agent, gen in zip(agents, generators):\n",
    "#     agent.env.generator = gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(agents[0].env.generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils.diff_evo import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open('./results/'+ name + '.pkl', 'wb+') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('./results/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# scores = {}\n",
    "# answers = {}\n",
    "\n",
    "\n",
    "# try:\n",
    "\n",
    "#     for j in range(5): # generations\n",
    "#         scores[j] = {}\n",
    "#         answers[j] = {}\n",
    "#         print('generating')\n",
    "#         for i, lvl in enumerate(generators):\n",
    "#             scores[j][i] = {}\n",
    "#             answers[j][i] = {}\n",
    "#             m, s = lvl.mutate(1)\n",
    "#             lvl.locations = m\n",
    "#             lvl.generation += 1\n",
    "#             lvl.to_file(i, game='dzelda')\n",
    "#             print(f'gen: {j}, lvl: {i}, \\n{str(lvl)}')\n",
    "\n",
    "#         print('training')\n",
    "#         for i, lvl in enumerate(generators):\n",
    "#             for a, agent in enumerate(agents):\n",
    "#                 agent.env.generator = lvl\n",
    "\n",
    "#                 objs = PyTorchObjective(agent)\n",
    "\n",
    "#                 start = time.time()\n",
    "#                 ans = differential_evolution(objs.fun, objs.bounds, \n",
    "#                                              strategy='rand1bin',\n",
    "#                                              popsize=49, \n",
    "#                                              maxiter=100,\n",
    "#                                              polish=False, \n",
    "#                                              x0=objs.x0)\n",
    "#                 end = time.time() - start\n",
    "\n",
    "#                 state_dict = objs.unpack_parameters(ans.x)\n",
    "#                 objs.f.load_state_dict(state_dict)\n",
    "\n",
    "#                 torch.save(objs.f, f'./levels/weights/weights_gen{j}_lvl{i}_agent{a}.pt')\n",
    "\n",
    "#                 # answers[generation][lvl][agentId]\n",
    "#                 answers[j][i][a] = {'ans':ans, 'agent':deepcopy(objs.f)}\n",
    "\n",
    "#         print('evaluating')\n",
    "#         # evaluate each agent on each env from this 'generation'\n",
    "#         for a, agent in enumerate(agents):\n",
    "#             # evaluate each agent with the generated levels this generation\n",
    "#             for i, lvl in enumerate(generators):\n",
    "#                 agent.env.generator = lvl\n",
    "#                 agent.nn = answers[j][i][a]['agent']\n",
    "#                 scores[j][i][a] = agent.fitness()\n",
    "\n",
    "#         save_obj(scores[j], f'gen{j}_scores')\n",
    "#         save_obj(answers[j], f'gen{j}_results')\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = PyTorchObjective(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import devo\n",
    "#import devo.jDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_gen = num_fn / popsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# # Try increasing the popsize argument by a lot. \n",
    "# result_02 = devo.jDE.run(\n",
    "#                         10000,\n",
    "#                         z.popsize,\n",
    "#                         0.5,\n",
    "#                         0.9,\n",
    "#                         z.fun_c,\n",
    "#                         z.x0.shape[0],\n",
    "#                         -5.0,\n",
    "#                         5.0,\n",
    "#                         z.create_population().ctypes.data_as(c.POINTER(c.c_double)),\n",
    "#                         z.init_fitnesses.ctypes.data_as(c.POINTER(c.c_double)),\n",
    "#                         z.results_callback\n",
    "#                         )\n",
    "\n",
    "# end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#result = [z.fun(x, len(x)).value for x in z.out_population]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z.out_fitnesses.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z.out_fitnesses.squeeze().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_result = np.argmin(z.out_fitnesses.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score = z.out_fitnesses[min_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_weights = z.out_population[min_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score, best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z.fun(best_weights, len(best_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z.x0 = best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict = z.unpack_parameters(z.x0)\n",
    "#z.f.load_state_dict(state_dict)\n",
    "# torch.save(z.f, f'./weights_gen{j}_lvl{i}_agent{a}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DE.run(\n",
    "    max_function_evaluations,\n",
    "    population_size,\n",
    "    scaling_factor,\n",
    "    crossover_rate,\n",
    "    objective_function,\n",
    "    problem_size,\n",
    "    lower_bound,\n",
    "    upper_bound,\n",
    "    init_population,\n",
    "    init_fitnesses,\n",
    "    result_callback,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_x.nn = torch.load(\"./dzelda_base_agent_150.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_x.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_x.env.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPARAMS = z.x0.shape[0]          # make this a 100-dimensinal problem.\n",
    "NPOPULATION = 5                # use population size of 101.\n",
    "MAX_ITERATION = 30             # run each solver for 5000 generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyms = [_x.mutate(0.0) for _ in range(NPOPULATION)]\n",
    "objs = [PyTorchObjective(a) for a in gyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(objective, weights):\n",
    "    return objective.fun(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from neat.parallel import ParallelEvaluator  # uses multiprocessing.Pool\n",
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(agent):\n",
    "    return agent.evalute()\n",
    "\n",
    "# # serial evaluation of all solutions\n",
    "# def serial_evals(X, f=fitness, args=()):\n",
    "#     return [f(x, *args) for x in X]\n",
    "\n",
    "# parallel evaluation of all solutions\n",
    "def _evaluate2(self, X, *args):\n",
    "    \"\"\"redefine evaluate without the dependencies on neat-internal data structures\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    for i, x in enumerate(X):\n",
    "        jobs.append(self.pool.apply_async(self.eval_function[i], (x, ) + args))\n",
    "    \n",
    "    return [job.get() for job in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParallelEvaluator.evaluate2 = _evaluate2\n",
    "parallel_eval = ParallelEvaluator(12, [obj.fun for obj in objs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2_w,5mirr1)-aCMA-ES (mu_w=1.6,w_1=73%) in dimension 9454 (seed=98910, Sun Dec 22 10:42:51 2019)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n"
     ]
    }
   ],
   "source": [
    "# time both\n",
    "for eval_all in [parallel_eval.evaluate2]:\n",
    "    es = cma.CMAEvolutionStrategy(NPARAMS * [1], 1, {'maxiter': MAX_ITERATION, \n",
    "                                                     'popsize': NPOPULATION})\n",
    "    es.disp_annotation()\n",
    "    while not es.stop():\n",
    "        X = es.ask()\n",
    "        es.tell(X, eval_all(X, len(X[0])))\n",
    "    es.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_solver(solver):\n",
    "    scores = {}\n",
    "    history = []\n",
    "    for j in tqdm(range(MAX_ITERATION)):\n",
    "        scores[j] = {}\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "        for i in range(solver.popsize):\n",
    "            fitness_list[i] = z.fun(solutions[i], len(solutions[i]))\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        \n",
    "        scores[j] = fitness_list\n",
    "        \n",
    "        if (j+1) % 100 == 0:\n",
    "            print(\"fitness at iteration\", (j+1), result[1])\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(scores)\n",
    "    df.to_csv(f'./{str(solver)}_fitness_scores_{MAX_ITERATION}gens.csv')       \n",
    "    \n",
    "    print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "    print(\"fitness score at this local optimum:\", result[1])\n",
    "    return history, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines genetic algorithm solver\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=100,           # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_history, result = test_solver(ga)\n",
    "\n",
    "plt.plot(ga_history)\n",
    "\n",
    "# result\n",
    "\n",
    "# oes = OpenES(NPARAMS,                  # number of model parameters\n",
    "#             sigma_init=0.5,            # initial standard deviation\n",
    "#             sigma_decay=0.999,         # don't anneal standard deviation\n",
    "#             learning_rate=0.1,         # learning rate for standard deviation\n",
    "#             learning_rate_decay = 1.0, # annealing the learning rate\n",
    "#             popsize=NPOPULATION,       # population size\n",
    "#             antithetic=False,          # whether to use antithetic sampling\n",
    "#             weight_decay=0.00,         # weight decay coefficient\n",
    "#             rank_fitness=False,        # use rank rather than fitness numbers\n",
    "#             forget_best=False)\n",
    "\n",
    "# oes_history, result = test_solver(oes)\n",
    "\n",
    "# plt.plot(oes_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(ga_history)\n",
    "\n",
    "z.fun(result[0], len(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from es import CMAES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cma = CMAES(NPARAMS, sigma_init=0.01, popsize=NPOPULATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cma_history, result = test_solver(cma)\n",
    "end = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cma_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(cma_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.fun(result[0], len(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end // 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.fun(z.x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.x0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.x0 = ans.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = z.unpack_parameters(ans.x)\n",
    "z.f.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.f == _x.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.env.prev_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.env.orientation[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.get_action(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents[3].env.generator = generators[2]\n",
    "t = agents[3].env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(action):\n",
    "    a, b, c, d = agents[3].env.step(action)\n",
    "    im = d['pic']\n",
    "    return im, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, r = move(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = _x.fitness(fn=show_state) if _x.env.pics else _x.fitness()\n",
    "_x.vis=None\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('winning_with_monster.npy', _x.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1600 * 1000 * 100 # frames seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(_x.nn, \"./dzelda_base_agent_150.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = []\n",
    "objs = []\n",
    "answers = []\n",
    "\n",
    "for i in range(1, 4):\n",
    "    t.append(NNagent(GridGame(game='dzelda', \n",
    "                      play_length=1000, \n",
    "                      path='./levels',\n",
    "                      lvl_name=f'{i}.txt',\n",
    "                      mechanics=['1', '2', '3', '+', 'g', 'w'], # monsters, key, door, wall\n",
    "                      images=False,\n",
    "                             )\n",
    "                    )\n",
    "            )\n",
    "    \n",
    "    if i == 1:\n",
    "        t[-1].nn = torch.load(\"./dzelda_base_agent_150.pt\")\n",
    "    else:\n",
    "        t[-1].nn = torch.load(f\"./dzelda_{i-1}_agent_{150*(i)}.pt\") #load previous best weights\n",
    "    \n",
    "    objs.append(PyTorchObjective(t[-1]))\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    ans = differential_evolution(objs[-1].fun, bounds, \n",
    "                                 strategy='rand1bin',\n",
    "                                 popsize=99, \n",
    "                                 maxiter=150,\n",
    "                                 polish=False, \n",
    "                                 x0=objs[-1].x0)\n",
    "    end = time.time() - start\n",
    "    \n",
    "    answers.append(ans)\n",
    "    state_dict = objs[-1].unpack_parameters(ans.x)\n",
    "    objs[-1].f.load_state_dict(state_dict)\n",
    "    \n",
    "    torch.save(t[-1].nn, f\"./dzelda_{i}_agent_{150*(i+1)}.pt\")\n",
    "    \n",
    "for pair in t:\n",
    "    pair.env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "First: Train an agent on an extremely simple level to give the agent a behavior starting point. \n",
    "    - In POET that was a flat terrain. In my case, it's a level that looks like this: \n",
    "    -   wwwwwwwwwwwww    \n",
    "        w...........w    A --> agent\n",
    "        w...........w    + --> key\n",
    "        w.+....A....w    g --> goal\n",
    "        w...........w\n",
    "        w...........w    Task: Take the key to the goal\n",
    "        w...........w\n",
    "        w.g.........w\n",
    "        wwwwwwwwwwwww\n",
    "        \n",
    "Second: Initialize agent-environment population with the first learned behavior\n",
    "    \n",
    "While True:\n",
    "    \n",
    "    Evaluate each agent in it's paired environment\n",
    "    \n",
    "    Mutate environments (every m loops). \n",
    "    \n",
    "        Mutation of an environment causes the agent neural network to be copied into the new environment\n",
    "        This increases the population.\n",
    "        \n",
    "        - An example mutation could be\n",
    "            - adding/removing in an enemy (three types)\n",
    "            - adding/moving a goal\n",
    "            - adding/removing a key\n",
    "            - moving an agent\n",
    "            - An example new level could look like this: \n",
    "                - wwwwwwwwwwwww    \n",
    "                  w....+..1...w    A --> agent\n",
    "                  w...g.......w    + --> key\n",
    "                  w...........w    g --> goal\n",
    "                  w...........w\n",
    "                  w...w.......w    Task: Take the key to the goal\n",
    "                  w.......A...w\n",
    "                  w.g.........w\n",
    "                  wwwwwwwwwwwww\n",
    "\n",
    "    (slowly) Run one step of optimization for each agent within it's paired environment.\n",
    "    \n",
    "    Transfer agents between environments (every k loops)\n",
    "        Intuition: Agent alpha might have learned behavior in it's paired environment that is actually behavior that is very good in environment beta. \n",
    "        \n",
    "        - test every agent in every environment. \n",
    "        - transfer into environment i, the agent j, who performed the best.\n",
    "    \n",
    "    Return to top of the loop.\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note. \n",
    "\n",
    "Moving the key from top right corner to mid left created a slightly simpler env.\n",
    "\n",
    "----  \n",
    "\n",
    "we were not able to learn the good policy if we kept the wieght range as [-2, 2]. \n",
    "\n",
    "Next I am retrying the same starting point but with range [-5, 5]. --> solved extremely simple env with this range and simpler env. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----  \n",
    "Then moving the key up one spot meant that the agent needs more training. So far it has failed to take the key and get to the goal after an additional 20 generations of training (but does get the key). I am giving it another 20 generations. \n",
    "\n",
    "After the agent learns the new environment (key moved up one spot), I am going to take those weights and put them back into the first env (key moved back down one spot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----  \n",
    "Note: There are times that the optimization straight up fails after only a generation or two. I think this is coming from the fact that the problem is very sparely rewarded.   \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited dzelda.txt: \n",
    "    - picking up key +1\n",
    "    - killing monster +1\n",
    "    - taking key to door +2\n",
    "\n",
    "\n",
    "1)  \n",
    "```\n",
    "wwwwwwwwwwwww\n",
    "w...........w\n",
    "w...........w\n",
    "w.+....A....w\n",
    "w...........w\n",
    "w...........w\n",
    "w...........w\n",
    "w.g.........w\n",
    "wwwwwwwwwwwww\n",
    "```\n",
    "2)   \n",
    "```\n",
    "wwwwwwwwwwwww\n",
    "w...........w\n",
    "w...........w\n",
    "w.+.........w\n",
    "w......A....w\n",
    "w...........w\n",
    "w...........w\n",
    "w.g.........w\n",
    "wwwwwwwwwwwww\n",
    "```\n",
    "\n",
    "3)  \n",
    "```\n",
    "wwwwwwwwwwwww\n",
    "w...........w\n",
    "w...........w\n",
    "w.+.........w\n",
    "w......A....w\n",
    "w...........w\n",
    "w..1........w\n",
    "w.g.........w\n",
    "wwwwwwwwwwwww\n",
    "```\n",
    "\n",
    "4)  \n",
    "```\n",
    "wwwwwwwwwwwww\n",
    "w...........w\n",
    "w...........w\n",
    "w.+.w.......w\n",
    "w...w..A....w\n",
    "w...........w\n",
    "w..1........w\n",
    "w.g.........w\n",
    "wwwwwwwwwwwww\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "```  \n",
    "   Net(\n",
    "      (conv1): Conv2d(13, 8, kernel_size=(3, 3), stride=(1, 1))\n",
    "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "      (conv2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1))\n",
    "      (fc1): Linear(in_features=96, out_features=48, bias=True)\n",
    "      (fc2): Linear(in_features=48, out_features=24, bias=True)\n",
    "      (fc3): Linear(in_features=24, out_features=6, bias=True)\n",
    "   )\n",
    "\n",
    "```\n",
    "\n",
    "# Differetial Evolution:\n",
    "\n",
    "## $\\theta :=$ model_weights  \n",
    "## Pick $\\theta_a, \\theta_b, \\theta_c$   \n",
    "## $Proposal_\\theta = \\theta_a + \\alpha * (\\theta_b - \\theta_c))$\n",
    "\n",
    "## Pros:\n",
    "Computationally efficient  \n",
    "Self-adaptation and crossover due to $\\theta_b - \\theta_c$\n",
    "\n",
    "## Problems:  \n",
    "\n",
    "$\\theta$ is a ~10000 dimensional vector. \n",
    "\n",
    "Curse of Dimensionality!   \n",
    "    - As the dimension go up, vectors become equidistant  \n",
    "\n",
    "Good weight configurations are sparse.\n",
    "\n",
    "Rewards are sparse.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation. Whenever the agent completes the goal, it seems to do so with the minimal path. That's suprising to me because we're giving the agent 1000 time-steps and the fitness function is not taking account (yet) of the number of steps that the agent has used as a weighting on the score it achieves. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
