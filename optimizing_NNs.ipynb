{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import optimize\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from collections import OrderedDict\n",
    "\n",
    "class PyTorchObjective(object):\n",
    "    \"\"\"PyTorch objective function, wrapped to be called by scipy.optimize.\"\"\"\n",
    "    def __init__(self, agent):\n",
    "        self.f = agent.nn # some pytorch module, that produces a scalar loss\n",
    "        # make an x0 from the parameters in this module\n",
    "        parameters = OrderedDict(agent.nn.named_parameters())\n",
    "        self.param_shapes = {n:parameters[n].size() for n in parameters}\n",
    "        # ravel and concatenate all parameters to make x0\n",
    "        self.x0 = np.concatenate([parameters[n].data.numpy().ravel() \n",
    "                                   for n in parameters])\n",
    "        \n",
    "        self.eval_fn = agent.evaluate\n",
    "\n",
    "    def unpack_parameters(self, x):\n",
    "        \"\"\"optimize.minimize will supply 1D array, chop it up for each parameter.\"\"\"\n",
    "        i = 0\n",
    "        named_parameters = OrderedDict()\n",
    "        for n in self.param_shapes:\n",
    "            param_len = reduce(lambda x,y: x*y, self.param_shapes[n])\n",
    "            # slice out a section of this length\n",
    "            param = x[i:i+param_len]\n",
    "            # reshape according to this size, and cast to torch\n",
    "            param = param.reshape(*self.param_shapes[n])\n",
    "            named_parameters[n] = torch.from_numpy(param)\n",
    "            # update index\n",
    "            i += param_len\n",
    "        return named_parameters\n",
    "\n",
    "    def pack_grads(self):\n",
    "        \"\"\"pack all the gradients from the parameters in the module into a\n",
    "        numpy array.\"\"\"\n",
    "        grads = []\n",
    "        for p in self.f.parameters():\n",
    "            grad = p.grad.data.numpy()\n",
    "            grads.append(grad.ravel())\n",
    "        return np.concatenate(grads)\n",
    "\n",
    "    def is_new(self, x):\n",
    "        # if this is the first thing we've seen\n",
    "        if not hasattr(self, 'cached_x'):\n",
    "            return True\n",
    "        else:\n",
    "            # compare x to cached_x to determine if we've been given a new input\n",
    "            x, self.cached_x = np.array(x), np.array(self.cached_x)\n",
    "            error = np.abs(x - self.cached_x)\n",
    "            return error.max() > 1e-8\n",
    "\n",
    "    def cache(self, x):\n",
    "        # unpack x and load into module \n",
    "        state_dict = self.unpack_parameters(x)\n",
    "        self.f.load_state_dict(state_dict)\n",
    "        # store the raw array as well\n",
    "        self.cached_x = x\n",
    "        # zero the gradient\n",
    "        self.f.zero_grad()\n",
    "        # use it to calculate the objective\n",
    "        obj = self.eval_fn()\n",
    "        # backprop the objective\n",
    "        # obj.backward()\n",
    "        self.cached_f = obj\n",
    "        return obj\n",
    "\n",
    "    def fun(self, x):\n",
    "        if self.is_new(x):\n",
    "            self.cache(x)\n",
    "        return self.cached_f\n",
    "\n",
    "    def jac(self, x):\n",
    "        if self.is_new(x):\n",
    "            self.cache(x)\n",
    "        return self.cached_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy import optimize\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # whatever this initialises to is our \"true\" W\n",
    "#     linear = nn.Linear(32,32)\n",
    "#     linear = linear.eval()\n",
    "\n",
    "#     # input X\n",
    "#     N = 10000\n",
    "#     X = torch.Tensor(N,32)\n",
    "#     X.uniform_(0.,1.) # fill with uniform\n",
    "#     eps = torch.Tensor(N,32)\n",
    "#     eps.normal_(0., 1e-4)\n",
    "\n",
    "#     # output Y\n",
    "#     with torch.no_grad():\n",
    "#         Y = linear(X) #+ eps\n",
    "\n",
    "#     # make module executing the experiment\n",
    "#     class Objective(nn.Module):\n",
    "#         def __init__(self):\n",
    "#             super(Objective, self).__init__()\n",
    "#             self.linear = nn.Linear(32,32)\n",
    "#             self.linear = self.linear.train()\n",
    "#             self.X, self.Y = X, Y\n",
    "\n",
    "#         def forward(self):\n",
    "#             output = self.linear(self.X)\n",
    "#             return F.mse_loss(output, self.Y).mean()\n",
    "\n",
    "#     objective = Objective()\n",
    "    \n",
    "#     maxiter = 100\n",
    "#     with tqdm(total=maxiter) as pbar:\n",
    "#         def verbose(xk):\n",
    "#             pbar.update(1)\n",
    "#         # try to optimize that function with scipy\n",
    "#         obj = PyTorchObjective(objective)\n",
    "#         xL = optimize.minimize(obj.fun, obj.x0, method='BFGS', jac=obj.jac,\n",
    "#                 callback=verbose, options={'gtol': 1e-6, 'disp': True,\n",
    "#                     'maxiter':maxiter})\n",
    "#         #xL = optimize.minimize(obj.fun, obj.x0, method='CG', jac=obj.jac)# , options={'gtol': 1e-2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_gvgai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.NNagent import NNagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.env_gen_wrapper import GridGame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to host 127.0.0.1 at port 42841 ...\n",
      "Client connected to server [OK]\n"
     ]
    }
   ],
   "source": [
    "_x = NNagent(GridGame(game='zelda', \n",
    "                     play_length=1000, \n",
    "                     path=gym_gvgai.dir + '/envs/games/zelda_v0/', \n",
    "                     lvl_name='zelda_lvl0.txt', \n",
    "                     mechanics=['1', '2', '3', '+', 'g', 'w'], # monsters, key, door, wall\n",
    "                  )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<agent.NNagent.NNagent at 0x7ba67ad01eb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(13, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=96, out_features=48, bias=True)\n",
       "  (fc2): Linear(in_features=48, out_features=24, bias=True)\n",
       "  (fc3): Linear(in_features=24, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = PyTorchObjective(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9262,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = _x.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = _x.get_action(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = z.unpack_parameters(np.random.randn(*z.x0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.f.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.cache(np.random.randn(*z.x0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.cached_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-1, 1)]*z.x0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-122a6dd1954e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferential_evolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#optimize.minimize(z.fun, z.x0, options={'maxiter':2})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/scipy/optimize/_differentialevolution.py\u001b[0m in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers)\u001b[0m\n\u001b[1;32m    269\u001b[0m                                      \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                                      \u001b[0mupdating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdating\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                                      workers=workers) as solver:\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/scipy/optimize/_differentialevolution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, maxfun, callback, disp, polish, init, atol, updating, workers)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'latinhypercube'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_population_lhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_population_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/site-packages/scipy/optimize/_differentialevolution.py\u001b[0m in \u001b[0;36minit_population_lhs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# Within each segment we sample from a uniform random distribution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# We need to do this sampling for each parameter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         samples = (segsize * rng.random_sample(self.population_shape)\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# Offset each segment to cover the entire parameter range [0, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ans = optimize.differential_evolution(z.fun, bounds, maxiter=1, popsize=2)\n",
    "\n",
    "#optimize.minimize(z.fun, z.x0, options={'maxiter':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
