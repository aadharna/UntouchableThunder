{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, step=0, name=\"\", info=\"\", image=None):\n",
    "    \"\"\"Fn to visualize the agent playing the game in a notebook\n",
    "    \"\"\"\n",
    "    plt.figure(10)\n",
    "    plt.clf()\n",
    "    if image is not None:\n",
    "        im = image\n",
    "    else:\n",
    "        im = env.render(mode=\"rgb_array\")[0]\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"{} | Step: {} {}\".format(name, step, info))\n",
    "    plt.axis('off')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import optimize\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from optimization.Optimizer import PyTorchObjective\n",
    "\n",
    "from baselines.common.vec_env.shmem_vec_env import ShmemVecEnv\n",
    "from utils.utils import zelda_spaces\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "from utils.diff_evo import differential_evolution\n",
    "\n",
    "from es import SimpleGA, OpenES\n",
    "\n",
    "import gym\n",
    "\n",
    "import gvgai\n",
    "\n",
    "from generator.levels.base import Generator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import ctypes as c\n",
    "\n",
    "from agent.base import Agent\n",
    "\n",
    "\n",
    "from scipy.optimize import Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.env_gen_wrapper import GridGame\n",
    "from agent.NNagent import NNagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = NNagent(GridGame(game='dzelda', \n",
    "                      play_length=1000, \n",
    "                      path='./levels',\n",
    "                      lvl_name='5.txt',\n",
    "                      mechanics=['+', 'g'], # monsters, key, door, wall\n",
    "                      images=True,\n",
    "                  ),\n",
    "             parent=torch.load('./results/RL/map5b/best/2.0/baseline_223_best_model_policy.pt')\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.nn = torch.load('./results/RL/map5b/best/2.0/baseline_59_best_model_policy.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.fitness(fn=show_state, rl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x.env.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#from cleanrl.common import preprocess_obs_space, preprocess_ac_space\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import gym\n",
    "import gvgai\n",
    "from gym.wrappers import TimeLimit, Monitor\n",
    "from gym.spaces import Discrete, Box, MultiBinary, MultiDiscrete, Space\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "from generator.env_gen_wrapper import GridGame\n",
    "from agent.NNagent import NNagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description='PPO agent')\n",
    "#     # Common arguments\n",
    "#     parser.add_argument('--exp-name', type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n",
    "#                        help='the name of this experiment')\n",
    "#     parser.add_argument('--gym-id', type=str, default=\"CartPole-v0\",\n",
    "#                        help='the id of the gym environment')\n",
    "#     parser.add_argument('--learning-rate', type=float, default=7e-4,\n",
    "#                        help='the learning rate of the optimizer')\n",
    "#     parser.add_argument('--seed', type=int, default=1,\n",
    "#                        help='seed of the experiment')\n",
    "#     parser.add_argument('--episode-length', type=int, default=0,\n",
    "#                        help='the maximum length of each episode')\n",
    "#     parser.add_argument('--total-timesteps', type=int, default=100000,\n",
    "#                        help='total timesteps of the experiments')\n",
    "#     parser.add_argument('--torch-deterministic', type=bool, default=True,\n",
    "#                        help='whether to set `torch.backends.cudnn.deterministic=True`')\n",
    "#     parser.add_argument('--cuda', type=bool, default=True,\n",
    "#                        help='whether to use CUDA whenever possible')\n",
    "#     parser.add_argument('--prod-mode', type=bool, default=False,\n",
    "#                        help='run the script in production mode and use wandb to log outputs')\n",
    "#     parser.add_argument('--capture-video', type=bool, default=False,\n",
    "#                        help='weather to capture videos of the agent performances (check out `videos` folder)')\n",
    "#     parser.add_argument('--wandb-project-name', type=str, default=\"cleanRL\",\n",
    "#                        help=\"the wandb's project name\")\n",
    "#     parser.add_argument('--wandb-entity', type=str, default=None,\n",
    "#                        help=\"the entity (team) of wandb's project\")\n",
    "\n",
    "#     # Algorithm specific arguments\n",
    "#     parser.add_argument('--gamma', type=float, default=0.99,\n",
    "#                        help='the discount factor gamma')\n",
    "#     parser.add_argument('--vf-coef', type=float, default=0.25,\n",
    "#                        help=\"value function's coefficient the loss function\")\n",
    "#     parser.add_argument('--max-grad-norm', type=float, default=0.5,\n",
    "#                        help='the maximum norm for the gradient clipping')\n",
    "#     parser.add_argument('--ent-coef', type=float, default=0.01,\n",
    "#                        help=\"policy entropy's coefficient the loss function\")\n",
    "#     parser.add_argument('--clip-coef', type=float, default=0.2,\n",
    "#                        help=\"the surrogate clipping coefficient\")\n",
    "#     parser.add_argument('--update-epochs', type=int, default=3,\n",
    "#                         help=\"the K epochs to update the policy\")\n",
    "#     args = parser.parse_args()\n",
    "#     if not args.seed:\n",
    "#         args.seed = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expname = 'lvl4'\n",
    "gym_id = 'dzelda'\n",
    "lr = 7e-4\n",
    "seed = 42\n",
    "episode_len = 250\n",
    "total_timesteps = 5000000\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "gamma = 0.99\n",
    "value_coeff = 0.25\n",
    "grad_norm = 0.5\n",
    "ent_coeff = 0.01\n",
    "clip = 0.2\n",
    "epoch_update = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridGame(game='dzelda', \n",
    "                      play_length=250, \n",
    "                      path='./levels',\n",
    "                      lvl_name='5.txt',\n",
    "                      mechanics=['+', 'g'], # monsters, key, door, wall\n",
    "                      images=False,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# https://github.com/hill-a/stable-baselines/blob/65ed3969e8859092e32e0cf89ac42959a7f283d6/stable_baselines/common/input.py#L6\n",
    "# https://github.com/hill-a/stable-baselines/blob/65ed3969e8859092e32e0cf89ac42959a7f283d6/stable_baselines/common/distributions.py#L182\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "import numpy as np\n",
    "from gym.spaces import Discrete, Box, MultiBinary, MultiDiscrete, Space\n",
    "\n",
    "def preprocess_obs_space(obs_space: Space, device: str):\n",
    "    \"\"\"\n",
    "    The `preprocess_obs_fn` receives the observation `x` in the shape of\n",
    "    `(batch_num,) + obs_space.shape`.\n",
    "    1) If the `obs_space` is `Discrete`, `preprocess_obs_fn` outputs a\n",
    "    preprocessed obs in the shape of\n",
    "    `(batch_num, obs_space.n)`.\n",
    "    2) If the `obs_space` is `Box`, `preprocess_obs_fn` outputs a\n",
    "    preprocessed obs in the shape of\n",
    "    `(batch_num,) + obs_space.shape`.\n",
    "    In addition, the preprocessed obs will be sent to `device` (either\n",
    "    `cpu` or `cuda`)\n",
    "    \"\"\"\n",
    "    if isinstance(obs_space, Discrete):\n",
    "        def preprocess_obs_fn(x):\n",
    "            return F.one_hot(torch.LongTensor(x), obs_space.n).float().to(device)\n",
    "        return (obs_space.n, preprocess_obs_fn)\n",
    "\n",
    "    elif isinstance(obs_space, Box):\n",
    "        def preprocess_obs_fn(x):\n",
    "            return torch.Tensor(x).float().view(torch.Tensor(x).shape[0], -1).to(device)\n",
    "        return (np.array(obs_space.shape).prod(), preprocess_obs_fn)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Error: the model does not support input space of type {}\".format(\n",
    "            type(obs_space).__name__))\n",
    "\n",
    "def preprocess_ac_space(ac_space: Space):\n",
    "    if isinstance(ac_space, Discrete):\n",
    "        return ac_space.n\n",
    "\n",
    "    elif isinstance(ac_space, MultiDiscrete):\n",
    "        return ac_space.nvec.sum()\n",
    "\n",
    "    elif isinstance(ac_space, Box):\n",
    "        return np.prod(ac_space.shape)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Error: the model does not support output space of type {}\".format(\n",
    "            type(ac_space).__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import zelda_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY NOT TO MODIFY: setup the environment\n",
    "experiment_name = f\"{gym_id}__{experiment_name}__{int(time.time())}\"\n",
    "writer = SummaryWriter(f\"./runs/{experiment_name}\")\n",
    "# writer.add_text('hyperparameters', \"|param|value|\\n|-|-|\\n%s\" % (\n",
    "#         '\\n'.join([f\"|{key}|{value}|\" for key, value in vars(args).items()])))\n",
    "# if args.prod_mode:\n",
    "#     import wandb\n",
    "#     wandb.init(project=args.wandb_project_name, entity=args.wandb_entity, tensorboard=True, config=vars(args), name=experiment_name, monitor_gym=True)\n",
    "#     writer = SummaryWriter(f\"/tmp/{experiment_name}\")\n",
    "#     wandb.save(os.path.abspath(__file__))\n",
    "\n",
    "# TRY NOT TO MODIFY: seeding\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#env = gym.make(args.gym_id)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "# input_shape = env.observation_space.shape[0]\n",
    "input_shape, preprocess_obs_fn = preprocess_obs_space(zelda_spaces[0], device)\n",
    "output_shape = preprocess_ac_space(zelda_spaces[1])\n",
    "# respect the default timelimit\n",
    "# if int(episode_len):\n",
    "#     if not isinstance(env, TimeLimit):\n",
    "#         env = TimeLimit(env, int(args.episode_length))\n",
    "#     else:\n",
    "#         env._max_episode_steps = int(episode_len)\n",
    "# else:\n",
    "#     args.episode_length = env._max_episode_steps if isinstance(env, TimeLimit) else 200\n",
    "    \n",
    "# if args.capture_video:\n",
    "#     env = Monitor(env, f'videos/{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value(nn.Module):\n",
    "    def __init__(self, depth):\n",
    "        super(Value, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=depth, out_channels=8, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3)\n",
    "        self.fc = nn.Linear((32 * 3) + 4, 1)\n",
    "\n",
    "    def forward(self, x, compass):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(len(x), 32 * 3)\n",
    "        x = torch.cat([x, compass], dim=1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = NNagent(GG=None, \n",
    "             parent=torch.load('./results/RL/ppo_test.pt'),\n",
    "             actions=6, depth=13)\n",
    "vf = Value(13)\n",
    "vf.double()\n",
    "optimizer = optim.Adam(list(pg.nn.parameters()) + list(vf.parameters()), lr=lr)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY NOT TO MODIFY: start the game\n",
    "global_step = 0\n",
    "while global_step < total_timesteps:\n",
    "    next_obs = np.array(env.reset())\n",
    "    actions = np.empty((episode_len,), dtype=object)\n",
    "    rewards, dones = np.zeros((2, episode_len))\n",
    "    obs = np.empty((episode_len,) + zelda_spaces[0].shape)\n",
    "    compass_info = np.empty((episode_len, 4))\n",
    "\n",
    "    # ALGO LOGIC: put other storage logic here\n",
    "    values = torch.zeros((episode_len), device=device)\n",
    "    neglogprobs = torch.zeros((episode_len,), device=device)\n",
    "    entropys = torch.zeros((episode_len,), device=device)\n",
    "\n",
    "    # TRY NOT TO MODIFY: prepare the execution of the game.\n",
    "    for step in range(episode_len):\n",
    "        global_step += 1\n",
    "        obs[step] = next_obs.copy()\n",
    "        \n",
    "        compass_info[step] = pg.compass_info\n",
    "\n",
    "        # ALGO LOGIC: put action logic here\n",
    "        values[step] = vf.forward(torch.DoubleTensor(obs[step:step+1]), \n",
    "                                  torch.DoubleTensor(compass_info[step:step+1]))\n",
    "\n",
    "        # ALGO LOGIC: `env.action_space` specific logic\n",
    "        action, neglogprob, entropy = pg.rl_get_action(torch.DoubleTensor(obs[step:step+1]), \n",
    "                                                       torch.DoubleTensor(compass_info[step:step+1]))\n",
    "        \n",
    "        actions[step], neglogprobs[step], entropys[step] = action.item(), neglogprob, entropy\n",
    "\n",
    "        # TRY NOT TO MODIFY: execute the game and log data.\n",
    "        next_obs, rewards[step], dones[step], _ = env.step(actions[step])\n",
    "        next_obs = np.array(next_obs)\n",
    "        if dones[step]:\n",
    "            break\n",
    "\n",
    "    # ALGO LOGIC: training.\n",
    "    # calculate the discounted rewards, or namely, returns\n",
    "    returns = np.zeros_like(rewards)\n",
    "    for t in reversed(range(rewards.shape[0]-1)):\n",
    "        returns[t] = rewards[t] + gamma * returns[t+1] * (1-dones[t])\n",
    "    # advantages are returns - baseline, value estimates in our case\n",
    "    advantages = returns - values.detach().cpu().numpy()\n",
    "\n",
    "    neglogprobs = neglogprobs.detach()\n",
    "    non_empty_idx = np.argmax(dones) + 1\n",
    "    for _ in range(epoch_update):\n",
    "        # ALGO LOGIC: `env.action_space` specific logic\n",
    "        _, new_neglogprobs, _ = pg.rl_get_action(torch.DoubleTensor(obs[:non_empty_idx]), \n",
    "                                                 torch.DoubleTensor(compass_info[:non_empty_idx]))\n",
    "        \n",
    "        ratio = torch.exp(neglogprobs[:non_empty_idx] - new_neglogprobs)\n",
    "        surrogate1 = ratio * torch.Tensor(advantages)[:non_empty_idx]\n",
    "        surrogate2 = torch.clamp(ratio, 1-clip, 1+clip) * torch.Tensor(advantages)[:non_empty_idx]\n",
    "        clip_value = torch.min(surrogate1, surrogate2)\n",
    "        vf_loss = loss_fn(torch.Tensor(returns), values) * value_coeff\n",
    "        loss = vf_loss - (clip_value + entropys[:non_empty_idx] * ent_coeff).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        nn.utils.clip_grad_norm_(list(pg.nn.parameters()) + list(vf.parameters()), grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
    "    writer.add_scalar(\"charts/episode_reward\", rewards.sum(), global_step)\n",
    "    writer.add_scalar(\"losses/value_loss\", vf_loss.item(), global_step)\n",
    "    writer.add_scalar(\"losses/entropy\", entropys[:step].mean().item(), global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pg.nn, \"./results/RL/ppo_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
